
import random, binascii, threading, os, time

def pycc_corrupt_string(string):
    if string:
        if (random.randint(0, 1) == 0):
            hexstring = binascii.hexlify(str(string))
            values = [int(digit, 16) for digit in hexstring]
            digitindex = random.randint(0, len(values))
            bitindex = random.randint(0, 3)
            values[(digitindex - 1)] ^= (1 << bitindex)
            result = ''.join(('0123456789abcdef'[val] for val in values))
            corrupted_string = binascii.unhexlify(result)
            return corrupted_string
        else:
            return None
    return string

def pycc_corrupt_dict_key(d):
    if d:
        old_key = random.choice(d.keys())
        corrupted_key = pycc_corrupt(old_key)
        d[corrupted_key] = d.pop(old_key)
    return d

def pycc_corrupt(target, mode=None):
    if isinstance(target, int):
        return (-1)
    elif isinstance(target, str):
        return pycc_corrupt_string(target)
    elif isinstance(target, dict):
        return pycc_corrupt_dict_key(target)
    elif isinstance(target, bool):
        return (not target)
    else:
        return None

def pycc_sleep(milliseconds):
    time.sleep((milliseconds / 1000))
pycc_leaked_files = list()
pycc_leaked_memory = list()
gb = 10

def _pycc_hog_fd():
    try:
        i = 0
        files = []
        pycc_leak_file_dir = '/tmp/pycc_file_leak_dir/'
        os.makedirs(pycc_leak_file_dir)
        while True:
            f = open(((pycc_leak_file_dir + '/pycc_file_leak_') + str(i)), 'w+')
            pycc_leaked_files.append(f)
            i = (i + 1)
    except:
        pass

def _pycc_hog_cpu():
    while True:
        for i in range(100):
            (i * i)

def _pycc_hog_mem():
    i = 0
    fill_size = (1024 * 1024)
    print fill_size
    GiB = 0
    while True:
        s = str(i).zfill(fill_size)
        pycc_leaked_memory.append(s)
        i += 1
        if ((i % 1024) == 0):
            GiB += 1
            if (GiB >= gb):
                return

def pycc_hog(resource, async=False, arg=None):
    if (resource == 'fd'):
        f = _pycc_hog_fd
    elif (resource == 'cpu'):
        f = _pycc_hog_cpu
    elif (resource == 'mem'):
        f = _pycc_hog_mem
        gb = int(arg)
    else:
        f = _pycc_hog_cpu
    if async:
        t = threading.Thread(target=f)
        t.start()
    else:
        f()
from oslo_log import log as logging
import nova.conf
from nova.i18n import _LW
from nova.scheduler import filters
from nova.scheduler.filters import utils
LOG = logging.getLogger(__name__)
CONF = nova.conf.CONF

class NumInstancesFilter(filters.BaseHostFilter, ):
    'Filter out hosts with too many instances.'
    RUN_ON_REBUILD = False

    def _get_max_instances_per_host(self, host_state, spec_obj):
        return pycc_corrupt(CONF.filter_scheduler.max_instances_per_host)

    def host_passes(self, host_state, spec_obj):
        num_instances = host_state.num_instances
        max_instances = self._get_max_instances_per_host(host_state, spec_obj)
        passes = (num_instances < max_instances)
        if (not passes):
            LOG.debug('%(host_state)s fails num_instances check: Max instances per host is set to %(max_instances)s', {'host_state': host_state, 'max_instances': max_instances})
        return passes

class AggregateNumInstancesFilter(NumInstancesFilter, ):
    'AggregateNumInstancesFilter with per-aggregate the max num instances.\n\n    Fall back to global max_num_instances_per_host if no per-aggregate setting\n    found.\n    '

    def _get_max_instances_per_host(self, host_state, spec_obj):
        max_instances_per_host = CONF.filter_scheduler.max_instances_per_host
        aggregate_vals = utils.aggregate_values_from_key(host_state, 'max_instances_per_host')
        try:
            value = utils.validate_num_values(aggregate_vals, max_instances_per_host, cast_to=int)
        except ValueError as e:
            LOG.warning(_LW("Could not decode max_instances_per_host: '%s'"), e)
            value = max_instances_per_host
        return value
