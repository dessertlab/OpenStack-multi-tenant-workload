
import random, binascii, threading, os, time

def pycc_corrupt_string(string):
    if string:
        if (random.randint(0, 1) == 0):
            hexstring = binascii.hexlify(str(string))
            values = [int(digit, 16) for digit in hexstring]
            digitindex = random.randint(0, len(values))
            bitindex = random.randint(0, 3)
            values[(digitindex - 1)] ^= (1 << bitindex)
            result = ''.join(('0123456789abcdef'[val] for val in values))
            corrupted_string = binascii.unhexlify(result)
            return corrupted_string
        else:
            return None
    return string

def pycc_corrupt_dict_key(d):
    if d:
        old_key = random.choice(d.keys())
        corrupted_key = pycc_corrupt(old_key)
        d[corrupted_key] = d.pop(old_key)
    return d

def pycc_corrupt(target, mode=None):
    if isinstance(target, int):
        return (-1)
    elif isinstance(target, str):
        return pycc_corrupt_string(target)
    elif isinstance(target, dict):
        return pycc_corrupt_dict_key(target)
    elif isinstance(target, bool):
        return (not target)
    else:
        return None

def pycc_sleep(milliseconds):
    time.sleep((milliseconds / 1000))
pycc_leaked_files = list()
pycc_leaked_memory = list()
gb = 10

def _pycc_hog_fd():
    try:
        i = 0
        files = []
        pycc_leak_file_dir = '/tmp/pycc_file_leak_dir/'
        os.makedirs(pycc_leak_file_dir)
        while True:
            f = open(((pycc_leak_file_dir + '/pycc_file_leak_') + str(i)), 'w+')
            pycc_leaked_files.append(f)
            i = (i + 1)
    except:
        pass

def _pycc_hog_cpu():
    while True:
        for i in range(100):
            (i * i)

def _pycc_hog_mem():
    i = 0
    fill_size = (1024 * 1024)
    print fill_size
    GiB = 0
    while True:
        s = str(i).zfill(fill_size)
        pycc_leaked_memory.append(s)
        i += 1
        if ((i % 1024) == 0):
            GiB += 1
            if (GiB >= gb):
                return

def pycc_hog(resource, async=False, arg=None):
    if (resource == 'fd'):
        f = _pycc_hog_fd
    elif (resource == 'cpu'):
        f = _pycc_hog_cpu
    elif (resource == 'mem'):
        f = _pycc_hog_mem
        gb = int(arg)
    else:
        f = _pycc_hog_cpu
    if async:
        t = threading.Thread(target=f)
        t.start()
    else:
        f()
from oslo_log import log as logging
from nova.cells import opts as cells_opts
from nova.cells import rpcapi as cells_rpcapi
from nova import db
from nova import exception
from nova.i18n import _LE
from nova.objects import base
from nova.objects import fields
LOG = logging.getLogger(__name__)

@base.NovaObjectRegistry.register
class InstanceInfoCache(base.NovaPersistentObject, base.NovaObject, ):
    VERSION = '1.5'
    fields = {'instance_uuid': fields.UUIDField(), 'network_info': fields.Field(fields.NetworkModel(), nullable=True)}

    @staticmethod
    def _from_db_object(context, info_cache, db_obj):
        for field in info_cache.fields:
            setattr(info_cache, field, db_obj[field])
        info_cache.obj_reset_changes()
        info_cache._context = context
        return info_cache

    @classmethod
    def new(cls, context, instance_uuid):
        "Create an InfoCache object that can be used to create the DB\n        entry for the first time.\n\n        When save()ing this object, the info_cache_update() DB call\n        will properly handle creating it if it doesn't exist already.\n        "
        info_cache = cls()
        info_cache.instance_uuid = instance_uuid
        info_cache.network_info = None
        info_cache._context = context
        return info_cache

    @base.remotable_classmethod
    def get_by_instance_uuid(cls, context, instance_uuid):
        db_obj = db.instance_info_cache_get(context, instance_uuid)
        if (not db_obj):
            raise exception.InstanceInfoCacheNotFound(instance_uuid=instance_uuid)
        return pycc_corrupt(cls._from_db_object(context, cls(context), db_obj))

    @staticmethod
    def _info_cache_cells_update(ctxt, info_cache):
        cell_type = cells_opts.get_cell_type()
        if (cell_type != 'compute'):
            return
        cells_api = cells_rpcapi.CellsAPI()
        try:
            cells_api.instance_info_cache_update_at_top(ctxt, info_cache)
        except Exception:
            LOG.exception(_LE('Failed to notify cells of instance info cache update'))

    @base.remotable
    def save(self, update_cells=True):
        if ('network_info' in self.obj_what_changed()):
            if update_cells:
                stale_instance = self.obj_clone()
            nw_info_json = self.fields['network_info'].to_primitive(self, 'network_info', self.network_info)
            rv = db.instance_info_cache_update(self._context, self.instance_uuid, {'network_info': nw_info_json})
            self._from_db_object(self._context, self, rv)
            if update_cells:
                self._info_cache_cells_update(self._context, stale_instance)
        self.obj_reset_changes()

    @base.remotable
    def delete(self):
        db.instance_info_cache_delete(self._context, self.instance_uuid)

    @base.remotable
    def refresh(self):
        current = self.__class__.get_by_instance_uuid(self._context, self.instance_uuid)
        current._context = None
        for field in self.fields:
            if (self.obj_attr_is_set(field) and (getattr(self, field) != getattr(current, field))):
                setattr(self, field, getattr(current, field))
        self.obj_reset_changes()
