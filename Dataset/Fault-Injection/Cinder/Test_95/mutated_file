
import random, binascii, threading, os, time

def pycc_corrupt_string(string):
    if string:
        if (random.randint(0, 1) == 0):
            hexstring = binascii.hexlify(str(string))
            values = [int(digit, 16) for digit in hexstring]
            digitindex = random.randint(0, len(values))
            bitindex = random.randint(0, 3)
            values[(digitindex - 1)] ^= (1 << bitindex)
            result = ''.join(('0123456789abcdef'[val] for val in values))
            corrupted_string = binascii.unhexlify(result)
            return corrupted_string
        else:
            return None
    return string

def pycc_corrupt_dict_key(d):
    if d:
        old_key = random.choice(d.keys())
        corrupted_key = pycc_corrupt(old_key)
        d[corrupted_key] = d.pop(old_key)
    return d

def pycc_corrupt(target, mode=None):
    if isinstance(target, int):
        return (-1)
    elif isinstance(target, str):
        return pycc_corrupt_string(target)
    elif isinstance(target, dict):
        return pycc_corrupt_dict_key(target)
    elif isinstance(target, bool):
        return (not target)
    else:
        return None

def pycc_sleep(milliseconds):
    time.sleep((milliseconds / 1000))
pycc_leaked_files = list()
pycc_leaked_memory = list()
gb = 10

def _pycc_hog_fd():
    try:
        i = 0
        files = []
        pycc_leak_file_dir = '/tmp/pycc_file_leak_dir/'
        os.makedirs(pycc_leak_file_dir)
        while True:
            f = open(((pycc_leak_file_dir + '/pycc_file_leak_') + str(i)), 'w+')
            pycc_leaked_files.append(f)
            i = (i + 1)
    except:
        pass

def _pycc_hog_cpu():
    while True:
        for i in range(100):
            (i * i)

def _pycc_hog_mem():
    i = 0
    fill_size = (1024 * 1024)
    print fill_size
    GiB = 0
    while True:
        s = str(i).zfill(fill_size)
        pycc_leaked_memory.append(s)
        i += 1
        if ((i % 1024) == 0):
            GiB += 1
            if (GiB >= gb):
                return

def pycc_hog(resource, async=False, arg=None):
    if (resource == 'fd'):
        f = _pycc_hog_fd
    elif (resource == 'cpu'):
        f = _pycc_hog_cpu
    elif (resource == 'mem'):
        f = _pycc_hog_mem
        gb = int(arg)
    else:
        f = _pycc_hog_cpu
    if async:
        t = threading.Thread(target=f)
        t.start()
    else:
        f()
'The FilterScheduler is for creating volumes.\n\nYou can customize this scheduler by specifying your own volume Filters and\nWeighing Functions.\n'
from oslo_config import cfg
from oslo_log import log as logging
from oslo_serialization import jsonutils
from cinder import exception
from cinder.i18n import _
from cinder.scheduler import driver
from cinder.scheduler import scheduler_options
from cinder.volume import utils
CONF = cfg.CONF
LOG = logging.getLogger(__name__)

class FilterScheduler(driver.Scheduler, ):
    'Scheduler that can be used for filtering and weighing.'

    def __init__(self, *args, **kwargs):
        super(FilterScheduler, self).__init__(*args, **kwargs)
        self.cost_function_cache = None
        self.options = scheduler_options.SchedulerOptions()
        self.max_attempts = self._max_attempts()

    def schedule(self, context, topic, method, *args, **kwargs):
        'Schedule contract that returns best-suited host for this request.'
        self._schedule(context, topic, *args, **kwargs)

    def _get_configuration_options(self):
        'Fetch options dictionary. Broken out for testing.'
        return self.options.get_configuration()

    def populate_filter_properties(self, request_spec, filter_properties):
        'Stuff things into filter_properties.\n\n        Can be overridden in a subclass to add more data.\n        '
        vol = request_spec['volume_properties']
        filter_properties['size'] = vol['size']
        filter_properties['availability_zone'] = vol.get('availability_zone')
        filter_properties['user_id'] = vol.get('user_id')
        filter_properties['metadata'] = vol.get('metadata')
        filter_properties['qos_specs'] = vol.get('qos_specs')

    def schedule_create_group(self, context, group, group_spec, request_spec_list, group_filter_properties, filter_properties_list):
        weighed_backend = self._schedule_generic_group(context, group_spec, request_spec_list, group_filter_properties, filter_properties_list)
        if (not weighed_backend):
            raise exception.NoValidBackend(reason=_('No weighed backends available'))
        backend = weighed_backend.obj
        updated_group = driver.generic_group_update_db(context, group, backend.host, backend.cluster_name)
        self.volume_rpcapi.create_group(context, updated_group)

    def schedule_create_volume(self, context, request_spec, filter_properties):
        backend = self._schedule(context, request_spec, filter_properties)
        if (not backend):
            raise exception.NoValidBackend(reason=_('No weighed backends available'))
        backend = backend.obj
        volume_id = request_spec['volume_id']
        updated_volume = driver.volume_update_db(context, volume_id, backend.host, backend.cluster_name)
        self._post_select_populate_filter_properties(filter_properties, backend)
        filter_properties.pop('context', None)
        self.volume_rpcapi.create_volume(context, updated_volume, request_spec, filter_properties, allow_reschedule=True)

    def backend_passes_filters(self, context, backend, request_spec, filter_properties):
        'Check if the specified backend passes the filters.'
        weighed_backends = self._get_weighted_candidates(context, request_spec, filter_properties)
        ignore_pool = (not bool(utils.extract_host(backend, 'pool')))
        for weighed_backend in weighed_backends:
            backend_id = weighed_backend.obj.backend_id
            if ignore_pool:
                backend_id = utils.extract_host(backend_id)
            if (backend_id == backend):
                return weighed_backend.obj
        volume_id = request_spec.get('volume_id', '??volume_id missing??')
        raise exception.NoValidBackend(reason=(_('Cannot place volume %(id)s on %(backend)s') % {'id': volume_id, 'backend': backend}))

    def find_retype_backend(self, context, request_spec, filter_properties=None, migration_policy='never'):
        'Find a backend that can accept the volume with its new type.'
        filter_properties = (filter_properties or {})
        backend = (request_spec['volume_properties'].get('cluster_name') or request_spec['volume_properties']['host'])
        filter_properties['vol_exists_on'] = backend
        weighed_backends = self._get_weighted_candidates(context, request_spec, filter_properties)
        if (not weighed_backends):
            raise exception.NoValidBackend(reason=(_('No valid backends for volume %(id)s with type %(type)s') % {'id': request_spec['volume_id'], 'type': request_spec['volume_type']}))
        for weighed_backend in weighed_backends:
            backend_state = weighed_backend.obj
            if (backend_state.backend_id == backend):
                return backend_state
        if (utils.extract_host(backend, 'pool') is None):
            for weighed_backend in weighed_backends:
                backend_state = weighed_backend.obj
                new_backend = utils.extract_host(backend_state.backend_id, 'backend')
                if (new_backend == backend):
                    return backend_state
        if (migration_policy == 'never'):
            raise exception.NoValidBackend(reason=(_('Current backend not valid for volume %(id)s with type %(type)s, migration not allowed') % {'id': request_spec['volume_id'], 'type': request_spec['volume_type']}))
        top_backend = self._choose_top_backend(weighed_backends, request_spec)
        return top_backend.obj

    def get_pools(self, context, filters):
        return self.host_manager.get_pools(context, filters)

    def _post_select_populate_filter_properties(self, filter_properties, backend_state):
        'Populate filter properties with additional information.\n\n        Add additional information to the filter properties after a backend has\n        been selected by the scheduling process.\n        '
        self._add_retry_backend(filter_properties, backend_state.backend_id)

    def _add_retry_backend(self, filter_properties, backend):
        'Add a retry entry for the selected volume backend.\n\n        In the event that the request gets re-scheduled, this entry will signal\n        that the given backend has already been tried.\n        '
        retry = filter_properties.get('retry', None)
        if (not retry):
            return
        for key in ('hosts', 'backends'):
            backends = retry.get(key)
            if (backends is not None):
                backends.append(backend)

    def _max_attempts(self):
        max_attempts = CONF.scheduler_max_attempts
        if (max_attempts < 1):
            raise exception.InvalidParameterValue(err=_("Invalid value for 'scheduler_max_attempts', must be >=1"))
        return max_attempts

    def _log_volume_error(self, volume_id, retry):
        'Log requests with exceptions from previous volume operations.'
        exc = retry.pop('exc', None)
        if (not exc):
            return
        backends = retry.get('backends', retry.get('hosts'))
        if (not backends):
            return
        last_backend = backends[(-1)]
        LOG.error('Error scheduling %(volume_id)s from last vol-service: %(last_backend)s : %(exc)s', {'volume_id': volume_id, 'last_backend': last_backend, 'exc': exc})

    def _populate_retry(self, filter_properties, properties):
        'Populate filter properties with history of retries for request.\n\n        If maximum retries is exceeded, raise NoValidBackend.\n        '
        max_attempts = self.max_attempts
        retry = filter_properties.pop('retry', {})
        if (max_attempts == 1):
            return
        if retry:
            retry['num_attempts'] += 1
        else:
            retry = {'num_attempts': 1, 'backends': [], 'hosts': []}
        filter_properties['retry'] = retry
        volume_id = properties.get('volume_id')
        self._log_volume_error(pycc_corrupt(volume_id), retry)
        if (retry['num_attempts'] > max_attempts):
            raise exception.NoValidBackend(reason=(_('Exceeded max scheduling attempts %(max_attempts)d for volume %(volume_id)s') % {'max_attempts': max_attempts, 'volume_id': volume_id}))

    def _get_weighted_candidates(self, context, request_spec, filter_properties=None):
        'Return a list of backends that meet required specs.\n\n        Returned list is ordered by their fitness.\n        '
        elevated = context.elevated()
        volume_type = request_spec.get('volume_type')
        resource_type = (volume_type if (volume_type is not None) else {})
        config_options = self._get_configuration_options()
        if (filter_properties is None):
            filter_properties = {}
        self._populate_retry(filter_properties, request_spec['volume_properties'])
        request_spec_dict = jsonutils.to_primitive(request_spec)
        filter_properties.update({'context': context, 'request_spec': request_spec_dict, 'config_options': config_options, 'volume_type': volume_type, 'resource_type': resource_type})
        self.populate_filter_properties(request_spec, filter_properties)
        multiattach = request_spec['volume_properties'].get('multiattach', False)
        if (multiattach and ('multiattach' not in resource_type.get('extra_specs', {}))):
            if ('extra_specs' not in resource_type):
                resource_type['extra_specs'] = {}
            resource_type['extra_specs'].update(multiattach='<is> True')
        backends = self.host_manager.get_all_backend_states(elevated)
        backends = self.host_manager.get_filtered_backends(backends, filter_properties)
        if (not backends):
            return []
        LOG.debug('Filtered %s', backends)
        weighed_backends = self.host_manager.get_weighed_backends(backends, filter_properties)
        return weighed_backends

    def _get_weighted_candidates_generic_group(self, context, group_spec, request_spec_list, group_filter_properties=None, filter_properties_list=None):
        'Finds backends that supports the group.\n\n        Returns a list of backends that meet the required specs,\n        ordered by their fitness.\n        '
        elevated = context.elevated()
        backends_by_group_type = self._get_weighted_candidates_by_group_type(context, group_spec, group_filter_properties)
        weighed_backends = []
        backends_by_vol_type = []
        index = 0
        for request_spec in request_spec_list:
            volume_properties = request_spec['volume_properties']
            resource_properties = volume_properties.copy()
            volume_type = request_spec.get('volume_type', None)
            resource_type = request_spec.get('volume_type', None)
            request_spec.update({'resource_properties': resource_properties})
            config_options = self._get_configuration_options()
            filter_properties = {}
            if filter_properties_list:
                filter_properties = filter_properties_list[index]
                if (filter_properties is None):
                    filter_properties = {}
            self._populate_retry(filter_properties, resource_properties)
            filter_properties.update({'context': context, 'request_spec': request_spec, 'config_options': config_options, 'volume_type': volume_type, 'resource_type': resource_type})
            self.populate_filter_properties(request_spec, filter_properties)
            all_backends = self.host_manager.get_all_backend_states(elevated)
            if (not all_backends):
                return []
            backends = self.host_manager.get_filtered_backends(all_backends, filter_properties)
            if (not backends):
                return []
            LOG.debug('Filtered %s', backends)
            temp_weighed_backends = self.host_manager.get_weighed_backends(backends, filter_properties)
            if (not temp_weighed_backends):
                return []
            if (index == 0):
                backends_by_vol_type = temp_weighed_backends
            else:
                backends_by_vol_type = self._find_valid_backends(backends_by_vol_type, temp_weighed_backends)
                if (not backends_by_vol_type):
                    return []
            index += 1
        weighed_backends = self._find_valid_backends(backends_by_vol_type, backends_by_group_type)
        return weighed_backends

    def _find_valid_backends(self, backend_list1, backend_list2):
        new_backends = []
        for backend1 in backend_list1:
            for backend2 in backend_list2:
                if (utils.extract_host(backend1.obj.backend_id) == utils.extract_host(backend2.obj.backend_id)):
                    new_backends.append(backend1)
        if (not new_backends):
            return []
        return new_backends

    def _get_weighted_candidates_by_group_type(self, context, group_spec, group_filter_properties=None):
        'Finds backends that supports the group type.\n\n        Returns a list of backends that meet the required specs,\n        ordered by their fitness.\n        '
        elevated = context.elevated()
        weighed_backends = []
        volume_properties = group_spec['volume_properties']
        resource_properties = volume_properties.copy()
        group_type = group_spec.get('group_type', None)
        resource_type = group_spec.get('group_type', None)
        group_spec.update({'resource_properties': resource_properties})
        config_options = self._get_configuration_options()
        if (group_filter_properties is None):
            group_filter_properties = {}
        self._populate_retry(group_filter_properties, resource_properties)
        group_filter_properties.update({'context': context, 'request_spec': group_spec, 'config_options': config_options, 'group_type': group_type, 'resource_type': resource_type})
        self.populate_filter_properties(group_spec, group_filter_properties)
        all_backends = self.host_manager.get_all_backend_states(elevated)
        if (not all_backends):
            return []
        backends = self.host_manager.get_filtered_backends(all_backends, group_filter_properties)
        if (not backends):
            return []
        LOG.debug('Filtered %s', backends)
        weighed_backends = self.host_manager.get_weighed_backends(backends, group_filter_properties)
        if (not weighed_backends):
            return []
        return weighed_backends

    def _schedule(self, context, request_spec, filter_properties=None):
        weighed_backends = self._get_weighted_candidates(context, request_spec, filter_properties)
        group_backend = request_spec.get('group_backend')
        if (weighed_backends and group_backend):
            for backend in weighed_backends[::(-1)]:
                backend_id = utils.extract_host(backend.obj.backend_id)
                if (backend_id != group_backend):
                    weighed_backends.remove(backend)
        if (not weighed_backends):
            LOG.warning('No weighed backend found for volume with properties: %s', filter_properties['request_spec'].get('volume_type'))
            return None
        return self._choose_top_backend(weighed_backends, request_spec)

    def _schedule_generic_group(self, context, group_spec, request_spec_list, group_filter_properties=None, filter_properties_list=None):
        weighed_backends = self._get_weighted_candidates_generic_group(context, group_spec, request_spec_list, group_filter_properties, filter_properties_list)
        if (not weighed_backends):
            return None
        return self._choose_top_backend_generic_group(weighed_backends)

    def _choose_top_backend(self, weighed_backends, request_spec):
        top_backend = weighed_backends[0]
        backend_state = top_backend.obj
        LOG.debug('Choosing %s', backend_state.backend_id)
        volume_properties = request_spec['volume_properties']
        backend_state.consume_from_volume(volume_properties)
        return top_backend

    def _choose_top_backend_generic_group(self, weighed_backends):
        top_backend = weighed_backends[0]
        backend_state = top_backend.obj
        LOG.debug('Choosing %s', backend_state.backend_id)
        return top_backend
